# Intro

I am a Pre-Doc MS student in Computer Science at the University of Chicago, advised by Prof. [**Junchen Jiang**](https://people.cs.uchicago.edu/~junchenj/). My research focuses on systems for large language models (LLMs) and computer networking. I am particularly interested in MLSys, which bridges the gap between rapidly developing machine learning algorithms and hardware. Previously, I was a visiting student at the University of Pennsylvania, where I worked closely with Dr. [Liangcheng Yu](https://liangchengyu.com/). I earned my B.E. in Information Engineering from Shanghai Jiao Tong University.

&nbsp;

I am one of the core contributors and maintainers of the following **open-source projects**:

- [LMCache](https://lmcache.ai/) (Stars 5.6k): The first high-performance KV cache management layer for distributed LLM inference.
- [vLLM production stack](https://docs.vllm.ai/projects/production-stack/en/latest/) (Stars 1.9k): vLLM’s reference system for K8S-native cluster-wide deployment.

# NEWS

<div class="news-box">

**[10/2025]** &nbsp;Attending <a href="NEWS
[10/2025]  Attending PyTorch Conference 2025 in San Francisco.

[10/2025]  LMCache technical report is live on arXiv!

[10/2025]  AdaptCache was presented at SOSP’25. Thanks Ganesh for the presentation!">PyTorch Conference 2025</a> in San Francisco.<br><br>
**[10/2025]** &nbsp;<a href='https://arxiv.org/pdf/2510.09665'>LMCache technical report</a> is now live on arXiv!<br><br>
**[10/2025]** &nbsp;<a href="https://docs.google.com/presentation/d/1UWIFYIoNfhqE6urXdPH-vCjwsN59L_UX/edit?usp=sharing&ouid=117429613749838892485&rtpof=true&sd=true">AdaptCache</a> was presented at SOSP’25. Thanks <a href="https://www.microsoft.com/en-us/research/people/ga/">Ganesh</a> for the presentation!<br><br>

</div>
